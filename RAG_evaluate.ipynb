{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3120b9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c2/912p1ty90qq72p_1fqvsx26c0000gn/T/ipykernel_59966/2360165371.py:3: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  model = ChatOllama(model=\"llama3.1:latest\", temperature=0)\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "model = ChatOllama(model=\"llama3.1:latest\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e47e645b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GOOGLE_API_KEY\"] = 'AIzaSyDRkqkksHo2Ctfo08fJynY9DfcpteabwqY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19508451",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/llamaenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "\n",
    "# === Step 1: Initialize Gemini LLM and embedding model ===\n",
    "# Create a Gemini 2.5 Pro chat model instance with temperature=0 (deterministic output)\n",
    "gemini_llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-pro\", temperature=0)\n",
    "\n",
    "# Create an embedding model using Gemini's embedding endpoint\n",
    "gemini_embedding = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "\n",
    "# === Step 2: Wrap them for RAGAS evaluation compatibility ===\n",
    "# Wrap the Gemini LLM with Langchain-style interface required by RAGAS\n",
    "evaluator_llm = LangchainLLMWrapper(gemini_llm)\n",
    "\n",
    "# Wrap the Gemini embedding model to make it usable by RAGAS embedding evaluation\n",
    "evaluator_embeddings = LangchainEmbeddingsWrapper(gemini_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9dee8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'user_input': 'Show me all the workflows in this domain biodiversity that has an associated tutorial', 'retrieved_contexts': [\"Document(metadata={'source': 'https://workflowhub.eu/workflows/656', 'team': 'PNDB', 'name': 'Biodiversity data exploration tutorial', 'relevance_score': 0.7593865}, page_content='@context: https://schema.org\\n@type.[0]: SoftwareSourceCode\\n@type.[1]: ComputationalWorkflow\\ndct:conformsTo: https://bioschemas.org/profiles/ComputationalWorkflow/1.0-RELEASE/\\n@id: https://workflowhub.eu/workflows/656\\ndescription: Galaxy Workflow created on Galaxy-E european instance, ecology.usegalaxy.eu, related to the Galaxy training tutorial [Biodiversity data exploration](https://training.galaxyproject.org/training-material/topics/ecology/tutorials/biodiversity-data-exploration/tutorial.html)\\r\\n\\r\\nThis workflow allows to explore biodiversity data looking at homoscedasticity, normality or collinearity of presences-absence or abundance data and at comparing beta diversity taking into account space, time and species components\\nname: Biodiversity data exploration tutorial\\nurl: https://workflowhub.eu/workflows/656\\nkeywords: \\nversion: 1\\nlicense: https://spdx.org/licenses/CC-BY-4.0\\ncreator.[0].@type: Person\\ncreator.[0].@id: https://workflowhub.eu/people/51\\ncreator.[0].name: Yvan Le Bras\\ncreator.[1].@type: Person\\ncreator.[1].@id: https://workflowhub.eu/people/52\\ncreator.[1].name: Coline Royaux\\ncreator.[2].@type: Person\\ncreator.[2].@id: #Marie%20Joss%C3%A9\\ncreator.[2].name: Marie Joss√©\\nproducer.[0].@type.[0]: Project\\nproducer.[0].@type.[1]: Organization\\nproducer.[0].@id: https://workflowhub.eu/projects/19\\nproducer.[0].name: PNDB\\ndateCreated: 2023-11-09T12:47:47Z\\ndateModified: 2023-11-09T12:47:47Z\\nprogrammingLanguage.@id: #galaxy\\nprogrammingLanguage.@type: ComputerLanguage\\nprogrammingLanguage.name: Galaxy')\", \"Document(metadata={'team': 'PNDB', 'name': 'Remote sensing Sentinel 2 data analysis to produce biodiversity metrics', 'source': 'https://workflowhub.eu/workflows/657', 'relevance_score': 0.657561}, page_content='@context: https://schema.org\\n@type.[0]: SoftwareSourceCode\\n@type.[1]: ComputationalWorkflow\\ndct:conformsTo: https://bioschemas.org/profiles/ComputationalWorkflow/1.0-RELEASE/\\n@id: https://workflowhub.eu/workflows/657\\ndescription: Galaxy Workflow created on Galaxy-E european instance, ecology.usegalaxy.eu, related to the Galaxy training tutorial [Sentinel 2 biodiversity](https://training.galaxyproject.org/training-material/topics/ecology/tutorials/species-distribution-modeling/tutorial.html) .\\r\\n\\r\\nThis workflow allows to analyze remote sensing sentinel 2 satellites data to compute spectral indices such as the NDVI and visualizing biodiversity indicators')\", \"Document(metadata={'name': 'Ecoregionalization on Antarctic sea', 'source': 'https://workflowhub.eu/workflows/658', 'team': 'PNDB', 'relevance_score': 0.61363083}, page_content='@context: https://schema.org\\n@type.[0]: SoftwareSourceCode\\n@type.[1]: ComputationalWorkflow\\ndct:conformsTo: https://bioschemas.org/profiles/ComputationalWorkflow/1.0-RELEASE/\\n@id: https://workflowhub.eu/workflows/658\\ndescription: \\r\\n\\r\\nGalaxy Workflow created on Galaxy-E european instance, ecology.usegalaxy.eu, related to the Galaxy training tutorial Antarctic sea ecoregionalization .\\r\\n\\r\\nThis workflow allows to analyze marine benthic biodiversity data to compute ecoregions regarding environmental data.')\", \"Document(metadata={'source': 'https://workflowhub.eu/workflows/662', 'team': 'PNDB', 'name': 'Obis biodiversity indicator on Asian pacific', 'relevance_score': 0.5726516}, page_content='@context: https://schema.org\\n@type.[0]: SoftwareSourceCode\\n@type.[1]: ComputationalWorkflow\\ndct:conformsTo: https://bioschemas.org/profiles/ComputationalWorkflow/1.0-RELEASE/\\n@id: https://workflowhub.eu/workflows/662\\ndescription: Galaxy Workflow created on Galaxy-E european instance, ecology.usegalaxy.eu, related to the Galaxy training tutorial [OBIS marine indicators](https://training.galaxyproject.org/training-material/topics/ecology/tutorials/obisindicators/tutorial.html) .\\r\\n\\r\\nThis workflow allows to compute and visualize marine biodiversity indicators from OBIS data.')\", \"Document(metadata={'source': 'https://workflowhub.eu/workflows/661', 'name': 'Boulder fields indicators', 'team': 'PNDB', 'relevance_score': 0.5486983}, page_content='@context: https://schema.org\\n@type.[0]: SoftwareSourceCode\\n@type.[1]: ComputationalWorkflow\\ndct:conformsTo: https://bioschemas.org/profiles/ComputationalWorkflow/1.0-RELEASE/\\n@id: https://workflowhub.eu/workflows/661\\ndescription: Galaxy Workflow created on Galaxy-E european instance, ecology.usegalaxy.eu, related to the Galaxy training tutorial [Champs blocs](https://training.galaxyproject.org/training-material/topics/ecology/tutorials/champs-blocs/tutorial.html) .\\r\\n\\r\\nThis workflow allows to produce Visual Rollover Indicator and dissimilarity as diversity indices on boulder fields.')\"], 'response': '### Workflow: Biodiversity data exploration tutorial This workflow explores biodiversity data by analyzing homoscedasticity, normality, or collinearity of presences-absence or abundance data, and comparing beta diversity while considering space, time, and species components. It is based on the Galaxy training tutorial [Biodiversity data exploration](https://training.galaxyproject.org/training-material/topics/ecology/tutorials/biodiversity-data-exploration/tutorial.html). ### Workflow: Remote sensing Sentinel 2 data analysis to produce biodiversity metrics This workflow analyzes remote sensing Sentinel-2 satellite data to compute spectral indices like NDVI and visualize biodiversity indicators. It is related to the Galaxy training tutorial [Sentinel 2 biodiversity](https://training.galaxyproject.org/training-material/topics/ecology/tutorials/species-distribution-modeling/tutorial.html). ### Workflow: Ecoregionalization on Antarctic sea This workflow analyzes marine benthic biodiversity data to compute ecoregions based on environmental data. It is related to the Galaxy training tutorial Antarctic sea ecoregionalization. ### Workflow: Obis biodiversity indicator on Asian pacific This workflow computes and visualizes marine biodiversity indicators from OBIS data, specifically for the Asian Pacific region. It is based on the Galaxy training tutorial [OBIS marine indicators](https://training.galaxyproject.org/training-material/topics/ecology/tutorials/obisindicators/tutorial.html). ### Workflow: Boulder fields indicators This workflow produces Visual Rollover Indicator and dissimilarity as diversity indices for boulder fields. It is related to the Galaxy training tutorial [Champs blocs](https://training.galaxyproject.org/training-material/topics/ecology/tutorials/champs-blocs/tutorial.html). **Summary:** There are five workflows associated with biodiversity, each linked to a specific Galaxy training tutorial and developed by the PNDB team. They cover various aspects of biodiversity analysis including data exploration, remote sensing for metrics, ecoregionalization in Antarctica, marine indicators from OBIS data (Asian Pacific focus), and producing diversity indices on boulder fields.'}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "with open(\"RAG_evaluate_dataset.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    dataset = json.load(f)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ad078df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import EvaluationDataset\n",
    "evaluation_dataset = EvaluationDataset.from_list(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d7f6dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [01:47<00:00, 53.59s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'faithfulness': 1.0000, 'llm_context_precision_without_reference': 0.6792}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "\n",
    "\n",
    "# evaluator_llm = LangchainLLMWrapper(model)\n",
    "from ragas.metrics import  Faithfulness, FactualCorrectness,LLMContextPrecisionWithoutReference,ResponseRelevancy\n",
    "\n",
    "result = evaluate(dataset=evaluation_dataset,metrics=[Faithfulness(),LLMContextPrecisionWithoutReference()],llm=evaluator_llm)\n",
    "result\n",
    "#ResponseRelevancy(), Faithfulness(),LLMContextPrecisionWithoutReference()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
